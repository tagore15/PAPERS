{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":998277,"sourceType":"datasetVersion","datasetId":547506}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-25T09:46:53.471527Z","iopub.execute_input":"2024-03-25T09:46:53.471996Z","iopub.status.idle":"2024-03-25T09:46:54.887294Z","shell.execute_reply.started":"2024-03-25T09:46:53.471961Z","shell.execute_reply":"2024-03-25T09:46:54.885952Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torchvision","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:42:33.010707Z","iopub.execute_input":"2024-03-25T06:42:33.012011Z","iopub.status.idle":"2024-03-25T06:42:41.267920Z","shell.execute_reply.started":"2024-03-25T06:42:33.011969Z","shell.execute_reply":"2024-03-25T06:42:41.266898Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import mobilenet_v2","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:42:41.269678Z","iopub.execute_input":"2024-03-25T06:42:41.270696Z","iopub.status.idle":"2024-03-25T06:42:41.278124Z","shell.execute_reply.started":"2024-03-25T06:42:41.270655Z","shell.execute_reply":"2024-03-25T06:42:41.276849Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model = mobilenet_v2(torchvision.models.MobileNet_V2_Weights.DEFAULT)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:42:41.280868Z","iopub.execute_input":"2024-03-25T06:42:41.282735Z","iopub.status.idle":"2024-03-25T06:42:41.794929Z","shell.execute_reply.started":"2024-03-25T06:42:41.282700Z","shell.execute_reply":"2024-03-25T06:42:41.793948Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n  warnings.warn(\nDownloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n100%|██████████| 13.6M/13.6M [00:00<00:00, 71.9MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"paths=[]\nlabels=[]\nfor dirname, _, filenames in os.walk('/kaggle/input/imagenetmini-1000/imagenet-mini/train'):\n    for filename in filenames:\n        if filename[-4:]=='JPEG':\n            paths+=[(os.path.join(dirname, filename))]\n            label=dirname.split('/')[-1]\n            labels+=[label]\n            \nclass_names=sorted(set(labels))\n#print(class_names)\nprint(len(class_names))\nN=list(range(len(class_names)))\nnormal_mapping=dict(zip(class_names,N)) \nreverse_mapping=dict(zip(N,class_names))    \n\ndf=pd.DataFrame(columns=['path','label'])\ndf['path']=paths\ndf['label']=labels\ndf['label']=df['label'].map(normal_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:42:41.796533Z","iopub.execute_input":"2024-03-25T06:42:41.797342Z","iopub.status.idle":"2024-03-25T06:43:06.873161Z","shell.execute_reply.started":"2024-03-25T06:42:41.797301Z","shell.execute_reply":"2024-03-25T06:43:06.871877Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1000\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe):\n        self.dataframe = dataframe\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        path = self.dataframe.loc[index, 'path']\n        label = self.dataframe.loc[index, 'label']\n        image = Image.open(path).convert('RGB')\n\n        transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                  std=[0.229, 0.224, 0.225])\n            ])\n        image = transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:43:06.875765Z","iopub.execute_input":"2024-03-25T06:43:06.876865Z","iopub.status.idle":"2024-03-25T06:43:06.886319Z","shell.execute_reply.started":"2024-03-25T06:43:06.876824Z","shell.execute_reply":"2024-03-25T06:43:06.885340Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nfrom torchvision.utils import make_grid\nfrom PIL import Image\n\ntrain_ds=CustomDataset(df)\ntrain_loader=DataLoader(train_ds,batch_size=32,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:43:06.887573Z","iopub.execute_input":"2024-03-25T06:43:06.887878Z","iopub.status.idle":"2024-03-25T06:43:06.907086Z","shell.execute_reply.started":"2024-03-25T06:43:06.887852Z","shell.execute_reply":"2024-03-25T06:43:06.905846Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch.optim import Adam\n\ncriterion=nn.CrossEntropyLoss()\noptimizer=Adam(model.classifier.parameters(),lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:43:06.908742Z","iopub.execute_input":"2024-03-25T06:43:06.909091Z","iopub.status.idle":"2024-03-25T06:43:06.918901Z","shell.execute_reply.started":"2024-03-25T06:43:06.909063Z","shell.execute_reply":"2024-03-25T06:43:06.917556Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch\nimport math\nfrom torch.autograd import Variable\nimport numpy as np\n\n\ndef group_product(xs, ys):\n    \"\"\"\n    the inner product of two lists of variables xs,ys\n    :param xs:\n    :param ys:\n    :return:\n    \"\"\"\n    return sum([torch.sum(x * y) for (x, y) in zip(xs, ys)])\n\n\ndef group_add(params, update, alpha=1):\n    \"\"\"\n    params = params + update*alpha\n    :param params: list of variable\n    :param update: list of data\n    :return:\n    \"\"\"\n    for i, p in enumerate(params):\n        params[i].data.add_(update[i] * alpha)\n    return params\n\n\ndef normalization(v):\n    \"\"\"\n    normalization of a list of vectors\n    return: normalized vectors v\n    \"\"\"\n    s = group_product(v, v)\n    s = s**0.5\n    s = s.cpu().item()\n    v = [vi / (s + 1e-6) for vi in v]\n    return v\n\n\ndef get_params_grad(model, layer_param):\n    \"\"\"\n    get model parameters and corresponding gradients\n    \"\"\"\n    params = []\n    grads = []\n    for param in layer_param:\n        if not param.requires_grad:\n            continue\n        params.append(param)\n        #print(\"Size:\", param.size())\n        #print(\"Grad:\", param.grad)\n        grads.append(0. if param.grad is None else param.grad + 0.)\n    return params, grads\n\n\ndef hessian_vector_product(gradsH, params, v):\n    \"\"\"\n    compute the hessian vector product of Hv, where\n    gradsH is the gradient at the current point,\n    params is the corresponding variables,\n    v is the vector.\n    \"\"\"\n    hv = torch.autograd.grad(gradsH,\n                             params,\n                             grad_outputs=v,\n                             only_inputs=True,\n                             retain_graph=True)\n    return hv\n\n\ndef orthnormal(w, v_list):\n    \"\"\"\n    make vector w orthogonal to each vector in v_list.\n    afterwards, normalize the output w\n    \"\"\"\n    for v in v_list:\n        w = group_add(w, v, alpha=-group_product(w, v))\n    return normalization(w)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:43:06.920826Z","iopub.execute_input":"2024-03-25T06:43:06.921532Z","iopub.status.idle":"2024-03-25T06:43:06.934997Z","shell.execute_reply.started":"2024-03-25T06:43:06.921500Z","shell.execute_reply":"2024-03-25T06:43:06.934147Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\nimport math\nfrom torch.autograd import Variable\nimport numpy as np\n\nclass hessian():\n    \"\"\"\n    The class used to compute :\n        i) the top 1 (n) eigenvalue(s) of the neural network\n        ii) the trace of the entire neural network\n        iii) the estimated eigenvalue density\n    \"\"\"\n\n    def __init__(self, model, criterion, layer_param, data=None, dataloader=None, cuda=True):\n        \"\"\"\n        model: the model that needs Hessain information\n        criterion: the loss function\n        data: a single batch of data, including inputs and its corresponding labels\n        dataloader: the data loader including bunch of batches of data\n        \"\"\"\n\n        # make sure we either pass a single batch or a dataloader\n        assert (data != None and dataloader == None) or (data == None and\n                                                         dataloader != None)\n\n        self.model = model.eval()  # make model is in evaluation model\n        self.criterion = criterion\n\n        if data != None:\n            self.data = data\n            self.full_dataset = False\n        else:\n            self.data = dataloader\n            self.full_dataset = True\n\n        if cuda:\n            self.device = 'cuda'\n        else:\n            self.device = 'cpu'\n\n        # pre-processing for single batch case to simplify the computation.\n        if not self.full_dataset:\n            self.inputs, self.targets = self.data\n            if self.device == 'cuda':\n                self.inputs, self.targets = self.inputs.cuda(\n                ), self.targets.cuda()\n\n            # if we only compute the Hessian information for a single batch data, we can re-use the gradients.\n            outputs = self.model(self.inputs)\n            loss = self.criterion(outputs, self.targets)\n            loss.backward(create_graph=True)\n\n        # this step is used to extract the parameters from the model\n        params, gradsH = get_params_grad(self.model, layer_param)\n        self.params = params\n        self.gradsH = gradsH  # gradient used for Hessian computation\n\n    def dataloader_hv_product(self, v):\n\n        device = self.device\n        num_data = 0  # count the number of datum points in the dataloader\n\n        THv = [torch.zeros(p.size()).to(device) for p in self.params\n              ]  # accumulate result\n        for inputs, targets in self.data:\n            self.model.zero_grad()\n            tmp_num_data = inputs.size(0)\n            outputs = self.model(inputs.to(device))\n            loss = self.criterion(outputs, targets.to(device))\n            loss.backward(create_graph=True)\n            params, gradsH = get_params_grad(self.model, self.params)\n            self.model.zero_grad()\n            Hv = torch.autograd.grad(gradsH,\n                                     params,\n                                     grad_outputs=v,\n                                     only_inputs=True,\n                                     retain_graph=False)\n            THv = [\n                THv1 + Hv1 * float(tmp_num_data) + 0.\n                for THv1, Hv1 in zip(THv, Hv)\n            ]\n            num_data += float(tmp_num_data)\n\n        THv = [THv1 / float(num_data) for THv1 in THv]\n        eigenvalue = group_product(THv, v).cpu().item()\n        return eigenvalue, THv\n\n    def eigenvalues(self, maxIter=5, tol=1e-3, top_n=1):\n        \"\"\"\n        compute the top_n eigenvalues using power iteration method\n        maxIter: maximum iterations used to compute each single eigenvalue\n        tol: the relative tolerance between two consecutive eigenvalue computations from power iteration\n        top_n: top top_n eigenvalues will be computed\n        \"\"\"\n\n        assert top_n >= 1\n\n        device = self.device\n\n        eigenvalues = []\n        eigenvectors = []\n\n        computed_dim = 0\n\n        while computed_dim < top_n:\n            eigenvalue = None\n            v = [torch.randn(p.size()).to(device) for p in self.params\n                ]  # generate random vector\n            v = normalization(v)  # normalize the vector\n\n            for i in range(maxIter):\n                v = orthnormal(v, eigenvectors)\n                self.model.zero_grad()\n\n                if self.full_dataset:\n                    tmp_eigenvalue, Hv = self.dataloader_hv_product(v)\n                else:\n                    Hv = hessian_vector_product(self.gradsH, self.params, v)\n                    tmp_eigenvalue = group_product(Hv, v).cpu().item()\n\n                v = normalization(Hv)\n\n                if eigenvalue == None:\n                    eigenvalue = tmp_eigenvalue\n                else:\n                    if abs(eigenvalue - tmp_eigenvalue) / (abs(eigenvalue) +\n                                                           1e-6) < tol:\n                        break\n                    else:\n                        eigenvalue = tmp_eigenvalue\n                print(f\"Iter:{i} EigenValue: {eigenvalue}\")\n            eigenvalues.append(eigenvalue)\n            eigenvectors.append(v)\n            computed_dim += 1\n\n        return eigenvalues, eigenvectors\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:43:06.937520Z","iopub.execute_input":"2024-03-25T06:43:06.937904Z","iopub.status.idle":"2024-03-25T06:43:06.964763Z","shell.execute_reply.started":"2024-03-25T06:43:06.937873Z","shell.execute_reply":"2024-03-25T06:43:06.963501Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:43:06.966482Z","iopub.execute_input":"2024-03-25T06:43:06.966933Z","iopub.status.idle":"2024-03-25T06:43:06.993556Z","shell.execute_reply.started":"2024-03-25T06:43:06.966896Z","shell.execute_reply":"2024-03-25T06:43:06.992509Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"MobileNetV2(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6(inplace=True)\n    )\n    (1): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (2): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (3): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (4): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (8): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (9): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (10): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (11): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (12): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (13): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (14): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (15): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (16): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (17): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (18): Conv2dNormActivation(\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6(inplace=True)\n    )\n  )\n  (classifier): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=1280, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"batch_num = 2\nhessian_dataloader = []\nfor i, (inputs, labels) in enumerate(train_loader):\n    hessian_dataloader.append((inputs, labels))\n    if i == batch_num - 1:\n        break\n\n#hessian_comp = hessian(model,\n#                       criterion,\n #                      dataloader=hessian_dataloader,\n #                      cuda=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:43:20.398600Z","iopub.execute_input":"2024-03-25T06:43:20.398987Z","iopub.status.idle":"2024-03-25T06:43:21.842818Z","shell.execute_reply.started":"2024-03-25T06:43:20.398958Z","shell.execute_reply":"2024-03-25T06:43:21.841525Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#top_eigenvalues, _ = hessian_comp.eigenvalues()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:02:23.121681Z","iopub.execute_input":"2024-03-24T14:02:23.126249Z","iopub.status.idle":"2024-03-24T14:02:23.132858Z","shell.execute_reply.started":"2024-03-24T14:02:23.126177Z","shell.execute_reply":"2024-03-24T14:02:23.131016Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#top_eigenvalues","metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:02:23.134929Z","iopub.execute_input":"2024-03-24T14:02:23.135563Z","iopub.status.idle":"2024-03-24T14:02:23.144467Z","shell.execute_reply.started":"2024-03-24T14:02:23.135511Z","shell.execute_reply":"2024-03-24T14:02:23.143099Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(inputs.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T06:43:47.524762Z","iopub.execute_input":"2024-03-25T06:43:47.525204Z","iopub.status.idle":"2024-03-25T06:43:47.530835Z","shell.execute_reply.started":"2024-03-25T06:43:47.525172Z","shell.execute_reply":"2024-03-25T06:43:47.529632Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"torch.Size([32, 3, 224, 224])\n","output_type":"stream"}]},{"cell_type":"code","source":"eig = []\nnames = []\nfor name, param in model.named_parameters():\n    if 'bias' in name:\n        continue\n    print(name, param.size())\n    try:\n        hessian_comp = hessian(model,\n                               criterion,\n                               [param],\n                               dataloader=hessian_dataloader,\n                               cuda=False)\n        top_eigenvalues, _ = hessian_comp.eigenvalues()\n    except:\n        continue\n    names.append(name)\n    eig.append(top_eigenvalues[0])\n    print(top_eigenvalues)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:02:23.148881Z","iopub.execute_input":"2024-03-24T14:02:23.149308Z","iopub.status.idle":"2024-03-24T16:49:35.645697Z","shell.execute_reply.started":"2024-03-24T14:02:23.149275Z","shell.execute_reply":"2024-03-24T16:49:35.644187Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"features.0.0.weight torch.Size([32, 3, 3, 3])\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1171.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"Iter:0 EigenValue: 0.07653722167015076\nIter:1 EigenValue: 6.205232620239258\nIter:2 EigenValue: 11.46668529510498\nIter:3 EigenValue: 11.971443176269531\nIter:4 EigenValue: 12.020084381103516\n[12.020084381103516]\nfeatures.0.1.weight torch.Size([32])\nIter:0 EigenValue: 0.019180288538336754\nIter:1 EigenValue: 0.13862453401088715\nIter:2 EigenValue: 0.2375819832086563\nIter:3 EigenValue: 0.2562798857688904\nIter:4 EigenValue: 0.2589285671710968\n[0.2589285671710968]\nfeatures.1.conv.0.0.weight torch.Size([32, 1, 3, 3])\nIter:0 EigenValue: 0.6842021942138672\nIter:1 EigenValue: 142.31919860839844\nIter:2 EigenValue: 189.2338409423828\nIter:3 EigenValue: 192.81280517578125\nIter:4 EigenValue: 193.35853576660156\n[193.35853576660156]\nfeatures.1.conv.0.1.weight torch.Size([32])\nIter:0 EigenValue: 0.014728409238159657\nIter:1 EigenValue: 0.10366059094667435\nIter:2 EigenValue: 0.177488774061203\nIter:3 EigenValue: 0.2206670492887497\nIter:4 EigenValue: 0.23718631267547607\n[0.23718631267547607]\nfeatures.1.conv.1.weight torch.Size([16, 32, 1, 1])\nIter:0 EigenValue: 0.18835194408893585\nIter:1 EigenValue: 40.28340148925781\nIter:2 EigenValue: 56.664554595947266\nIter:3 EigenValue: 57.680580139160156\nIter:4 EigenValue: 57.76768112182617\n[57.76768112182617]\nfeatures.1.conv.2.weight torch.Size([16])\nIter:0 EigenValue: 0.00843628216534853\nIter:1 EigenValue: 0.027302701026201248\nIter:2 EigenValue: 0.03130132332444191\nIter:3 EigenValue: 0.03223561495542526\nIter:4 EigenValue: 0.03252466395497322\n[0.03252466395497322]\nfeatures.2.conv.0.0.weight torch.Size([96, 16, 1, 1])\nIter:0 EigenValue: 0.008790317922830582\nIter:1 EigenValue: 0.41594964265823364\nIter:2 EigenValue: 0.5994700193405151\nIter:3 EigenValue: 0.6807416677474976\nIter:4 EigenValue: 0.7360883951187134\n[0.7360883951187134]\nfeatures.2.conv.0.1.weight torch.Size([96])\nIter:0 EigenValue: 0.03009287267923355\nIter:1 EigenValue: 0.41679367423057556\nIter:2 EigenValue: 0.49905723333358765\nIter:3 EigenValue: 0.5188259482383728\nIter:4 EigenValue: 0.5247716307640076\n[0.5247716307640076]\nfeatures.2.conv.1.0.weight torch.Size([96, 1, 3, 3])\nIter:0 EigenValue: 0.46162301301956177\nIter:1 EigenValue: 139.9661865234375\nIter:2 EigenValue: 145.41355895996094\nIter:3 EigenValue: 146.1674346923828\nIter:4 EigenValue: 146.32432556152344\n[146.32432556152344]\nfeatures.2.conv.1.1.weight torch.Size([96])\nIter:0 EigenValue: 0.054091453552246094\nIter:1 EigenValue: 0.2668077051639557\nIter:2 EigenValue: 0.28392133116722107\nIter:3 EigenValue: 0.28689810633659363\nIter:4 EigenValue: 0.28886109590530396\n[0.28886109590530396]\nfeatures.2.conv.2.weight torch.Size([24, 96, 1, 1])\nIter:0 EigenValue: 0.08610434830188751\nIter:1 EigenValue: 28.434412002563477\nIter:2 EigenValue: 48.186981201171875\nIter:3 EigenValue: 61.828819274902344\nIter:4 EigenValue: 65.56151580810547\n[65.56151580810547]\nfeatures.2.conv.3.weight torch.Size([24])\nIter:0 EigenValue: 0.006521183997392654\nIter:1 EigenValue: 0.013230087235569954\nIter:2 EigenValue: 0.015125197358429432\nIter:3 EigenValue: 0.01555654127150774\nIter:4 EigenValue: 0.01586723141372204\n[0.01586723141372204]\nfeatures.3.conv.0.0.weight torch.Size([144, 24, 1, 1])\nIter:0 EigenValue: 0.005245069973170757\nIter:1 EigenValue: 0.880359411239624\nIter:2 EigenValue: 1.3165258169174194\nIter:3 EigenValue: 1.496741533279419\nIter:4 EigenValue: 1.5916213989257812\n[1.5916213989257812]\nfeatures.3.conv.0.1.weight torch.Size([144])\nIter:0 EigenValue: 0.014013618230819702\nIter:1 EigenValue: 0.1101619079709053\nIter:2 EigenValue: 0.12754276394844055\nIter:3 EigenValue: 0.14209656417369843\nIter:4 EigenValue: 0.1607772558927536\n[0.1607772558927536]\nfeatures.3.conv.1.0.weight torch.Size([144, 1, 3, 3])\nIter:0 EigenValue: 0.18451395630836487\nIter:1 EigenValue: 24.128469467163086\nIter:2 EigenValue: 29.73061180114746\nIter:3 EigenValue: 31.617395401000977\nIter:4 EigenValue: 32.1727180480957\n[32.1727180480957]\nfeatures.3.conv.1.1.weight torch.Size([144])\nIter:0 EigenValue: 0.00918846856802702\nIter:1 EigenValue: 0.21538372337818146\nIter:2 EigenValue: 0.2601243257522583\nIter:3 EigenValue: 0.26678016781806946\nIter:4 EigenValue: 0.2698800265789032\n[0.2698800265789032]\nfeatures.3.conv.2.weight torch.Size([24, 144, 1, 1])\nIter:0 EigenValue: 0.11359693109989166\nIter:1 EigenValue: 27.10372543334961\nIter:2 EigenValue: 37.630760192871094\nIter:3 EigenValue: 40.98332214355469\nIter:4 EigenValue: 41.725914001464844\n[41.725914001464844]\nfeatures.3.conv.3.weight torch.Size([24])\nIter:0 EigenValue: 0.0036870024632662535\nIter:1 EigenValue: 0.0064781587570905685\nIter:2 EigenValue: 0.008080760017037392\nIter:3 EigenValue: 0.009050507098436356\nIter:4 EigenValue: 0.00958317518234253\n[0.00958317518234253]\nfeatures.4.conv.0.0.weight torch.Size([144, 24, 1, 1])\nIter:0 EigenValue: 0.007155353203415871\nIter:1 EigenValue: 0.4125700891017914\nIter:2 EigenValue: 0.6752259135246277\nIter:3 EigenValue: 0.8402118682861328\nIter:4 EigenValue: 0.926040768623352\n[0.926040768623352]\nfeatures.4.conv.0.1.weight torch.Size([144])\nIter:0 EigenValue: 0.02047901041805744\nIter:1 EigenValue: 0.19463776051998138\nIter:2 EigenValue: 0.2137586623430252\nIter:3 EigenValue: 0.21809248626232147\nIter:4 EigenValue: 0.21952709555625916\n[0.21952709555625916]\nfeatures.4.conv.1.0.weight torch.Size([144, 1, 3, 3])\nIter:0 EigenValue: 0.02467772364616394\nIter:1 EigenValue: 3.234977960586548\nIter:2 EigenValue: 4.375637531280518\nIter:3 EigenValue: 4.658383369445801\nIter:4 EigenValue: 4.732873439788818\n[4.732873439788818]\nfeatures.4.conv.1.1.weight torch.Size([144])\nIter:0 EigenValue: 0.01063871942460537\nIter:1 EigenValue: 0.061926379799842834\nIter:2 EigenValue: 0.08158395439386368\nIter:3 EigenValue: 0.08898913860321045\nIter:4 EigenValue: 0.09352141618728638\n[0.09352141618728638]\nfeatures.4.conv.2.weight torch.Size([32, 144, 1, 1])\nIter:0 EigenValue: 0.02806323766708374\nIter:1 EigenValue: 7.181842803955078\nIter:2 EigenValue: 8.453685760498047\nIter:3 EigenValue: 8.876550674438477\nIter:4 EigenValue: 9.161972045898438\n[9.161972045898438]\nfeatures.4.conv.3.weight torch.Size([32])\nIter:0 EigenValue: 0.002923004562035203\nIter:1 EigenValue: 0.00831325352191925\nIter:2 EigenValue: 0.009282799437642097\nIter:3 EigenValue: 0.009391030296683311\nIter:4 EigenValue: 0.009414905682206154\n[0.009414905682206154]\nfeatures.5.conv.0.0.weight torch.Size([192, 32, 1, 1])\nIter:0 EigenValue: 0.0017466435674577951\nIter:1 EigenValue: 0.16490338742733002\nIter:2 EigenValue: 0.2313796430826187\nIter:3 EigenValue: 0.2529159486293793\nIter:4 EigenValue: 0.2607848346233368\n[0.2607848346233368]\nfeatures.5.conv.0.1.weight torch.Size([192])\nIter:0 EigenValue: 0.0033046440221369267\nIter:1 EigenValue: 0.0550495907664299\nIter:2 EigenValue: 0.0711936205625534\nIter:3 EigenValue: 0.07688463479280472\nIter:4 EigenValue: 0.07897025346755981\n[0.07897025346755981]\nfeatures.5.conv.1.0.weight torch.Size([192, 1, 3, 3])\nIter:0 EigenValue: 0.029309753328561783\nIter:1 EigenValue: 7.316254615783691\nIter:2 EigenValue: 12.928068161010742\nIter:3 EigenValue: 14.202417373657227\nIter:4 EigenValue: 14.446484565734863\n[14.446484565734863]\nfeatures.5.conv.1.1.weight torch.Size([192])\nIter:0 EigenValue: 0.0020074655767530203\nIter:1 EigenValue: 0.015041099861264229\nIter:2 EigenValue: 0.026679379865527153\nIter:3 EigenValue: 0.03199222683906555\nIter:4 EigenValue: 0.03391598165035248\n[0.03391598165035248]\nfeatures.5.conv.2.weight torch.Size([32, 192, 1, 1])\nIter:0 EigenValue: 0.026189200580120087\nIter:1 EigenValue: 12.355128288269043\nIter:2 EigenValue: 15.782662391662598\nIter:3 EigenValue: 16.73394012451172\nIter:4 EigenValue: 17.206804275512695\n[17.206804275512695]\nfeatures.5.conv.3.weight torch.Size([32])\nIter:0 EigenValue: 0.0011003428371623158\nIter:1 EigenValue: 0.0018627250101417303\nIter:2 EigenValue: 0.002434130758047104\nIter:3 EigenValue: 0.0027169850654900074\nIter:4 EigenValue: 0.0028559600468724966\n[0.0028559600468724966]\nfeatures.6.conv.0.0.weight torch.Size([192, 32, 1, 1])\nIter:0 EigenValue: 0.0014507536543533206\nIter:1 EigenValue: 0.19541341066360474\nIter:2 EigenValue: 0.2875291705131531\nIter:3 EigenValue: 0.3424327075481415\nIter:4 EigenValue: 0.3820854425430298\n[0.3820854425430298]\nfeatures.6.conv.0.1.weight torch.Size([192])\nIter:0 EigenValue: 0.003841561498120427\nIter:1 EigenValue: 0.08658983558416367\nIter:2 EigenValue: 0.2251790314912796\nIter:3 EigenValue: 0.2392541617155075\nIter:4 EigenValue: 0.23992376029491425\n[0.23992376029491425]\nfeatures.6.conv.1.0.weight torch.Size([192, 1, 3, 3])\nIter:0 EigenValue: 0.02085801027715206\nIter:1 EigenValue: 3.35148024559021\nIter:2 EigenValue: 4.50652551651001\nIter:3 EigenValue: 4.693599700927734\nIter:4 EigenValue: 4.744227886199951\n[4.744227886199951]\nfeatures.6.conv.1.1.weight torch.Size([192])\nIter:0 EigenValue: 0.0026420876383781433\nIter:1 EigenValue: 0.027613170444965363\nIter:2 EigenValue: 0.03899221867322922\nIter:3 EigenValue: 0.04188218712806702\nIter:4 EigenValue: 0.042699865996837616\n[0.042699865996837616]\nfeatures.6.conv.2.weight torch.Size([32, 192, 1, 1])\nIter:0 EigenValue: 0.013134680688381195\nIter:1 EigenValue: 9.57261848449707\nIter:2 EigenValue: 12.191216468811035\nIter:3 EigenValue: 12.64745044708252\nIter:4 EigenValue: 12.731514930725098\n[12.731514930725098]\nfeatures.6.conv.3.weight torch.Size([32])\nIter:0 EigenValue: 0.000877518905326724\nIter:1 EigenValue: 0.0012721478706225753\nIter:2 EigenValue: 0.0015764018753543496\nIter:3 EigenValue: 0.00184000248555094\nIter:4 EigenValue: 0.0020906622521579266\n[0.0020906622521579266]\nfeatures.7.conv.0.0.weight torch.Size([192, 32, 1, 1])\nIter:0 EigenValue: 0.00484582781791687\nIter:1 EigenValue: 0.8844932913780212\nIter:2 EigenValue: 1.1512072086334229\nIter:3 EigenValue: 1.1911556720733643\nIter:4 EigenValue: 1.201429009437561\n[1.201429009437561]\nfeatures.7.conv.0.1.weight torch.Size([192])\nIter:0 EigenValue: 0.016336437314748764\nIter:1 EigenValue: 0.10899442434310913\nIter:2 EigenValue: 0.13726858794689178\nIter:3 EigenValue: 0.14617568254470825\nIter:4 EigenValue: 0.15089640021324158\n[0.15089640021324158]\nfeatures.7.conv.1.0.weight torch.Size([192, 1, 3, 3])\nIter:0 EigenValue: 0.00872228853404522\nIter:1 EigenValue: 0.6982861161231995\nIter:2 EigenValue: 1.0197328329086304\nIter:3 EigenValue: 1.0853519439697266\nIter:4 EigenValue: 1.103651523590088\n[1.103651523590088]\nfeatures.7.conv.1.1.weight torch.Size([192])\nIter:0 EigenValue: 0.008032622747123241\nIter:1 EigenValue: 0.035651806741952896\nIter:2 EigenValue: 0.050005462020635605\nIter:3 EigenValue: 0.05965784937143326\nIter:4 EigenValue: 0.06603848934173584\n[0.06603848934173584]\nfeatures.7.conv.2.weight torch.Size([64, 192, 1, 1])\nIter:0 EigenValue: 0.025054235011339188\nIter:1 EigenValue: 21.883390426635742\nIter:2 EigenValue: 28.015140533447266\nIter:3 EigenValue: 28.908557891845703\nIter:4 EigenValue: 29.172117233276367\n[29.172117233276367]\nfeatures.7.conv.3.weight torch.Size([64])\nIter:0 EigenValue: 0.001096345135010779\nIter:1 EigenValue: 0.003427439136430621\nIter:2 EigenValue: 0.004639635793864727\nIter:3 EigenValue: 0.005031626671552658\nIter:4 EigenValue: 0.005200496409088373\n[0.005200496409088373]\nfeatures.8.conv.0.0.weight torch.Size([384, 64, 1, 1])\nIter:0 EigenValue: 0.0006803611177019775\nIter:1 EigenValue: 0.3561739921569824\nIter:2 EigenValue: 0.5815165042877197\nIter:3 EigenValue: 0.6635124683380127\nIter:4 EigenValue: 0.690223217010498\n[0.690223217010498]\nfeatures.8.conv.0.1.weight torch.Size([384])\nIter:0 EigenValue: 0.0007594323251396418\nIter:1 EigenValue: 0.012140507809817791\nIter:2 EigenValue: 0.021953295916318893\nIter:3 EigenValue: 0.02397247776389122\nIter:4 EigenValue: 0.02529505081474781\n[0.02529505081474781]\nfeatures.8.conv.1.0.weight torch.Size([384, 1, 3, 3])\nIter:0 EigenValue: 0.036037612706422806\nIter:1 EigenValue: 16.519123077392578\nIter:2 EigenValue: 17.573118209838867\nIter:3 EigenValue: 17.649394989013672\n[17.649394989013672]\nfeatures.8.conv.1.1.weight torch.Size([384])\nIter:0 EigenValue: 0.0006737267249263823\nIter:1 EigenValue: 0.009381036274135113\nIter:2 EigenValue: 0.0166592039167881\nIter:3 EigenValue: 0.020830698311328888\nIter:4 EigenValue: 0.02209979109466076\n[0.02209979109466076]\nfeatures.8.conv.2.weight torch.Size([64, 384, 1, 1])\nIter:0 EigenValue: 0.0020444118417799473\nIter:1 EigenValue: 3.7782750129699707\nIter:2 EigenValue: 5.396636962890625\nIter:3 EigenValue: 5.836969375610352\nIter:4 EigenValue: 5.9670820236206055\n[5.9670820236206055]\nfeatures.8.conv.3.weight torch.Size([64])\nIter:0 EigenValue: 0.0007355493726208806\nIter:1 EigenValue: 0.0018195690354332328\nIter:2 EigenValue: 0.002564595080912113\nIter:3 EigenValue: 0.0031221085228025913\nIter:4 EigenValue: 0.003486169967800379\n[0.003486169967800379]\nfeatures.9.conv.0.0.weight torch.Size([384, 64, 1, 1])\nIter:0 EigenValue: 0.0008579583372920752\nIter:1 EigenValue: 0.428084135055542\nIter:2 EigenValue: 0.6707844138145447\nIter:3 EigenValue: 0.7620382905006409\nIter:4 EigenValue: 0.7905381321907043\n[0.7905381321907043]\nfeatures.9.conv.0.1.weight torch.Size([384])\nIter:0 EigenValue: 0.0013500925851985812\nIter:1 EigenValue: 0.02622719295322895\nIter:2 EigenValue: 0.04288254678249359\nIter:3 EigenValue: 0.04824647307395935\nIter:4 EigenValue: 0.04941481351852417\n[0.04941481351852417]\nfeatures.9.conv.1.0.weight torch.Size([384, 1, 3, 3])\nIter:0 EigenValue: 0.012109880335628986\nIter:1 EigenValue: 1.776923418045044\nIter:2 EigenValue: 2.278364658355713\nIter:3 EigenValue: 2.386437177658081\nIter:4 EigenValue: 2.421663999557495\n[2.421663999557495]\nfeatures.9.conv.1.1.weight torch.Size([384])\nIter:0 EigenValue: 0.0010294716339558363\nIter:1 EigenValue: 0.01103132963180542\nIter:2 EigenValue: 0.015423480421304703\nIter:3 EigenValue: 0.01748962141573429\nIter:4 EigenValue: 0.019560981541872025\n[0.019560981541872025]\nfeatures.9.conv.2.weight torch.Size([64, 384, 1, 1])\nIter:0 EigenValue: 0.004498226102441549\nIter:1 EigenValue: 5.760863304138184\nIter:2 EigenValue: 7.159247398376465\nIter:3 EigenValue: 7.429349422454834\nIter:4 EigenValue: 7.490782737731934\n[7.490782737731934]\nfeatures.9.conv.3.weight torch.Size([64])\nIter:0 EigenValue: 0.0005619137082248926\nIter:1 EigenValue: 0.0015665754908695817\nIter:2 EigenValue: 0.002198129193857312\nIter:3 EigenValue: 0.002678022952750325\nIter:4 EigenValue: 0.0029905817937105894\n[0.0029905817937105894]\nfeatures.10.conv.0.0.weight torch.Size([384, 64, 1, 1])\nIter:0 EigenValue: 0.000601313600782305\nIter:1 EigenValue: 0.5263761878013611\nIter:2 EigenValue: 1.3509514331817627\nIter:3 EigenValue: 1.403009057044983\nIter:4 EigenValue: 1.4053727388381958\n[1.4053727388381958]\nfeatures.10.conv.0.1.weight torch.Size([384])\nIter:0 EigenValue: 0.002131581539288163\nIter:1 EigenValue: 0.06725631654262543\nIter:2 EigenValue: 0.07447328418493271\nIter:3 EigenValue: 0.07543227821588516\nIter:4 EigenValue: 0.07567454129457474\n[0.07567454129457474]\nfeatures.10.conv.1.0.weight torch.Size([384, 1, 3, 3])\nIter:0 EigenValue: 0.012094991281628609\nIter:1 EigenValue: 2.222622871398926\nIter:2 EigenValue: 2.5689029693603516\nIter:3 EigenValue: 2.621772289276123\nIter:4 EigenValue: 2.630671977996826\n[2.630671977996826]\nfeatures.10.conv.1.1.weight torch.Size([384])\nIter:0 EigenValue: 0.0015611457638442516\nIter:1 EigenValue: 0.023199263960123062\nIter:2 EigenValue: 0.02728986367583275\nIter:3 EigenValue: 0.028013670817017555\nIter:4 EigenValue: 0.02856256254017353\n[0.02856256254017353]\nfeatures.10.conv.2.weight torch.Size([64, 384, 1, 1])\nIter:0 EigenValue: 0.007758787367492914\nIter:1 EigenValue: 5.846062660217285\nIter:2 EigenValue: 7.837161064147949\nIter:3 EigenValue: 8.907827377319336\nIter:4 EigenValue: 9.438218116760254\n[9.438218116760254]\nfeatures.10.conv.3.weight torch.Size([64])\nIter:0 EigenValue: 0.0006462560268118978\nIter:1 EigenValue: 0.0027360329404473305\nIter:2 EigenValue: 0.0029992414638400078\nIter:3 EigenValue: 0.00304286926984787\nIter:4 EigenValue: 0.0030615967698395252\n[0.0030615967698395252]\nfeatures.11.conv.0.0.weight torch.Size([384, 64, 1, 1])\nIter:0 EigenValue: 0.001788877067156136\nIter:1 EigenValue: 1.6718394756317139\nIter:2 EigenValue: 2.1228249073028564\nIter:3 EigenValue: 2.1431822776794434\n[2.1431822776794434]\nfeatures.11.conv.0.1.weight torch.Size([384])\nIter:0 EigenValue: 0.0023951937910169363\nIter:1 EigenValue: 0.08502290397882462\nIter:2 EigenValue: 0.11284184455871582\nIter:3 EigenValue: 0.11463852971792221\nIter:4 EigenValue: 0.11478827148675919\n[0.11478827148675919]\nfeatures.11.conv.1.0.weight torch.Size([384, 1, 3, 3])\nIter:0 EigenValue: 0.01188794057816267\nIter:1 EigenValue: 1.4348556995391846\nIter:2 EigenValue: 1.9656341075897217\nIter:3 EigenValue: 2.2170541286468506\nIter:4 EigenValue: 2.362485885620117\n[2.362485885620117]\nfeatures.11.conv.1.1.weight torch.Size([384])\nIter:0 EigenValue: 0.003099234774708748\nIter:1 EigenValue: 0.02651824802160263\nIter:2 EigenValue: 0.037893928587436676\nIter:3 EigenValue: 0.04311761632561684\nIter:4 EigenValue: 0.045433420687913895\n[0.045433420687913895]\nfeatures.11.conv.2.weight torch.Size([96, 384, 1, 1])\nIter:0 EigenValue: 0.01300722360610962\nIter:1 EigenValue: 14.511857986450195\nIter:2 EigenValue: 18.254053115844727\nIter:3 EigenValue: 19.235748291015625\nIter:4 EigenValue: 19.73572540283203\n[19.73572540283203]\nfeatures.11.conv.3.weight torch.Size([96])\nIter:0 EigenValue: 0.0010222196578979492\nIter:1 EigenValue: 0.004050665535032749\nIter:2 EigenValue: 0.004999939352273941\nIter:3 EigenValue: 0.005426382180303335\nIter:4 EigenValue: 0.005764532368630171\n[0.005764532368630171]\nfeatures.12.conv.0.0.weight torch.Size([576, 96, 1, 1])\nIter:0 EigenValue: 0.000648898771032691\nIter:1 EigenValue: 0.4800814986228943\nIter:2 EigenValue: 0.8239219188690186\nIter:3 EigenValue: 1.059899926185608\nIter:4 EigenValue: 1.1692461967468262\n[1.1692461967468262]\nfeatures.12.conv.0.1.weight torch.Size([576])\nIter:0 EigenValue: 0.0020833380986005068\nIter:1 EigenValue: 0.03021104820072651\nIter:2 EigenValue: 0.040348172187805176\nIter:3 EigenValue: 0.043881773948669434\nIter:4 EigenValue: 0.045125894248485565\n[0.045125894248485565]\nfeatures.12.conv.1.0.weight torch.Size([576, 1, 3, 3])\nIter:0 EigenValue: 0.010800165124237537\nIter:1 EigenValue: 1.51683509349823\nIter:2 EigenValue: 1.7190924882888794\nIter:3 EigenValue: 1.7562613487243652\nIter:4 EigenValue: 1.775297999382019\n[1.775297999382019]\nfeatures.12.conv.1.1.weight torch.Size([576])\nIter:0 EigenValue: 0.00147897785063833\nIter:1 EigenValue: 0.013491125777363777\nIter:2 EigenValue: 0.017761461436748505\nIter:3 EigenValue: 0.020436301827430725\nIter:4 EigenValue: 0.022969011217355728\n[0.022969011217355728]\nfeatures.12.conv.2.weight torch.Size([96, 576, 1, 1])\nIter:0 EigenValue: 0.006696696393191814\nIter:1 EigenValue: 10.426959991455078\nIter:2 EigenValue: 12.965975761413574\nIter:3 EigenValue: 13.698270797729492\nIter:4 EigenValue: 13.969958305358887\n[13.969958305358887]\nfeatures.12.conv.3.weight torch.Size([96])\nIter:0 EigenValue: 0.000701639917679131\nIter:1 EigenValue: 0.0021055550314486027\nIter:2 EigenValue: 0.0025897540617734194\nIter:3 EigenValue: 0.0027465918101370335\nIter:4 EigenValue: 0.002832077443599701\n[0.002832077443599701]\nfeatures.13.conv.0.0.weight torch.Size([576, 96, 1, 1])\nIter:0 EigenValue: 0.0006957408040761948\nIter:1 EigenValue: 0.4361604154109955\nIter:2 EigenValue: 0.588656485080719\nIter:3 EigenValue: 0.6655386686325073\nIter:4 EigenValue: 0.7076644897460938\n[0.7076644897460938]\nfeatures.13.conv.0.1.weight torch.Size([576])\nIter:0 EigenValue: 0.0019953895825892687\nIter:1 EigenValue: 0.035096265375614166\nIter:2 EigenValue: 0.04780568554997444\nIter:3 EigenValue: 0.051032766699790955\nIter:4 EigenValue: 0.05260264873504639\n[0.05260264873504639]\nfeatures.13.conv.1.0.weight torch.Size([576, 1, 3, 3])\nIter:0 EigenValue: 0.006965432316064835\nIter:1 EigenValue: 3.6185054779052734\nIter:2 EigenValue: 5.593072891235352\nIter:3 EigenValue: 5.661564826965332\n[5.661564826965332]\nfeatures.13.conv.1.1.weight torch.Size([576])\nIter:0 EigenValue: 0.001967052463442087\nIter:1 EigenValue: 0.029312118887901306\nIter:2 EigenValue: 0.046681057661771774\nIter:3 EigenValue: 0.05343303084373474\nIter:4 EigenValue: 0.055585265159606934\n[0.055585265159606934]\nfeatures.13.conv.2.weight torch.Size([96, 576, 1, 1])\nIter:0 EigenValue: 0.013744140043854713\nIter:1 EigenValue: 20.763851165771484\nIter:2 EigenValue: 27.742494583129883\nIter:3 EigenValue: 30.915000915527344\nIter:4 EigenValue: 33.203643798828125\n[33.203643798828125]\nfeatures.13.conv.3.weight torch.Size([96])\nIter:0 EigenValue: 0.0003643480013124645\nIter:1 EigenValue: 0.0014437425415962934\nIter:2 EigenValue: 0.0019404393387958407\nIter:3 EigenValue: 0.002087435917928815\nIter:4 EigenValue: 0.002133817644789815\n[0.002133817644789815]\nfeatures.14.conv.0.0.weight torch.Size([576, 96, 1, 1])\nIter:0 EigenValue: 0.001308809733018279\nIter:1 EigenValue: 0.8959843516349792\nIter:2 EigenValue: 1.2700519561767578\nIter:3 EigenValue: 1.401872158050537\nIter:4 EigenValue: 1.4526314735412598\n[1.4526314735412598]\nfeatures.14.conv.0.1.weight torch.Size([576])\nIter:0 EigenValue: 0.005851424299180508\nIter:1 EigenValue: 0.0629630982875824\nIter:2 EigenValue: 0.09664622694253922\nIter:3 EigenValue: 0.11275911331176758\nIter:4 EigenValue: 0.11953937262296677\n[0.11953937262296677]\nfeatures.14.conv.1.0.weight torch.Size([576, 1, 3, 3])\nIter:0 EigenValue: 0.005274448078125715\nIter:1 EigenValue: 0.50953209400177\nIter:2 EigenValue: 0.6702528595924377\nIter:3 EigenValue: 0.7205567359924316\nIter:4 EigenValue: 0.7386818528175354\n[0.7386818528175354]\nfeatures.14.conv.1.1.weight torch.Size([576])\nIter:0 EigenValue: 0.004490202758461237\nIter:1 EigenValue: 0.03601126745343208\nIter:2 EigenValue: 0.05034177005290985\nIter:3 EigenValue: 0.05624618008732796\nIter:4 EigenValue: 0.05947273224592209\n[0.05947273224592209]\nfeatures.14.conv.2.weight torch.Size([160, 576, 1, 1])\nIter:0 EigenValue: 0.018786879256367683\nIter:1 EigenValue: 62.13190460205078\nIter:2 EigenValue: 93.89796447753906\nIter:3 EigenValue: 99.99400329589844\nIter:4 EigenValue: 103.42398071289062\n[103.42398071289062]\nfeatures.14.conv.3.weight torch.Size([160])\nIter:0 EigenValue: 0.0007972656167112291\nIter:1 EigenValue: 0.003855826798826456\nIter:2 EigenValue: 0.005416856613010168\nIter:3 EigenValue: 0.005791895091533661\nIter:4 EigenValue: 0.0058836559765040874\n[0.0058836559765040874]\nfeatures.15.conv.0.0.weight torch.Size([960, 160, 1, 1])\nIter:0 EigenValue: 0.0005129422061145306\nIter:1 EigenValue: 1.0253676176071167\nIter:2 EigenValue: 1.5585975646972656\nIter:3 EigenValue: 1.845216989517212\nIter:4 EigenValue: 2.0242624282836914\n[2.0242624282836914]\nfeatures.15.conv.0.1.weight torch.Size([960])\nIter:0 EigenValue: 0.0021932332310825586\nIter:1 EigenValue: 0.09321895241737366\nIter:2 EigenValue: 0.14949926733970642\nIter:3 EigenValue: 0.16155347228050232\nIter:4 EigenValue: 0.16394808888435364\n[0.16394808888435364]\nfeatures.15.conv.1.0.weight torch.Size([960, 1, 3, 3])\nIter:0 EigenValue: 0.01110069826245308\nIter:1 EigenValue: 4.051684856414795\nIter:2 EigenValue: 5.2106218338012695\nIter:3 EigenValue: 5.453952789306641\nIter:4 EigenValue: 5.511298179626465\n[5.511298179626465]\nfeatures.15.conv.1.1.weight torch.Size([960])\nIter:0 EigenValue: 0.0018522747559472919\nIter:1 EigenValue: 0.034903690218925476\nIter:2 EigenValue: 0.04617532715201378\nIter:3 EigenValue: 0.05104845017194748\nIter:4 EigenValue: 0.05412787199020386\n[0.05412787199020386]\nfeatures.15.conv.2.weight torch.Size([160, 960, 1, 1])\nIter:0 EigenValue: 0.0037603930104523897\nIter:1 EigenValue: 10.262594223022461\nIter:2 EigenValue: 21.51084327697754\nIter:3 EigenValue: 34.326637268066406\nIter:4 EigenValue: 38.19676971435547\n[38.19676971435547]\nfeatures.15.conv.3.weight torch.Size([160])\nIter:0 EigenValue: 0.0006488108192570508\nIter:1 EigenValue: 0.002752577420324087\nIter:2 EigenValue: 0.0036672616843134165\nIter:3 EigenValue: 0.003980558831244707\nIter:4 EigenValue: 0.004143805708736181\n[0.004143805708736181]\nfeatures.16.conv.0.0.weight torch.Size([960, 160, 1, 1])\nIter:0 EigenValue: 0.0008003928232938051\nIter:1 EigenValue: 2.1684131622314453\nIter:2 EigenValue: 2.832413673400879\nIter:3 EigenValue: 3.0141537189483643\nIter:4 EigenValue: 3.089956760406494\n[3.089956760406494]\nfeatures.16.conv.0.1.weight torch.Size([960])\nIter:0 EigenValue: 0.004695403389632702\nIter:1 EigenValue: 0.09141955524682999\nIter:2 EigenValue: 0.14825087785720825\nIter:3 EigenValue: 0.19366343319416046\nIter:4 EigenValue: 0.21281060576438904\n[0.21281060576438904]\nfeatures.16.conv.1.0.weight torch.Size([960, 1, 3, 3])\nIter:0 EigenValue: 0.009907891042530537\nIter:1 EigenValue: 12.648741722106934\nIter:2 EigenValue: 16.76831817626953\nIter:3 EigenValue: 16.842077255249023\n[16.842077255249023]\nfeatures.16.conv.1.1.weight torch.Size([960])\nIter:0 EigenValue: 0.0038567157462239265\nIter:1 EigenValue: 0.08333241939544678\nIter:2 EigenValue: 0.19339390099048615\nIter:3 EigenValue: 0.2453811764717102\nIter:4 EigenValue: 0.25379931926727295\n[0.25379931926727295]\nfeatures.16.conv.2.weight torch.Size([160, 960, 1, 1])\nIter:0 EigenValue: 0.0129398787394166\nIter:1 EigenValue: 182.94076538085938\nIter:2 EigenValue: 286.55218505859375\nIter:3 EigenValue: 296.823486328125\nIter:4 EigenValue: 297.74566650390625\n[297.74566650390625]\nfeatures.16.conv.3.weight torch.Size([160])\nIter:0 EigenValue: 0.0004608562448993325\nIter:1 EigenValue: 0.0017748711397871375\nIter:2 EigenValue: 0.0025819502770900726\nIter:3 EigenValue: 0.002993019064888358\nIter:4 EigenValue: 0.0031452407129108906\n[0.0031452407129108906]\nfeatures.17.conv.0.0.weight torch.Size([960, 160, 1, 1])\nIter:0 EigenValue: 0.0010749390348792076\nIter:1 EigenValue: 2.053112030029297\nIter:2 EigenValue: 2.4235727787017822\nIter:3 EigenValue: 2.637712240219116\nIter:4 EigenValue: 2.8952584266662598\n[2.8952584266662598]\nfeatures.17.conv.0.1.weight torch.Size([960])\nIter:0 EigenValue: 0.003244888735935092\nIter:1 EigenValue: 0.08364669978618622\nIter:2 EigenValue: 0.20788997411727905\nIter:3 EigenValue: 0.26745912432670593\nIter:4 EigenValue: 0.2763209640979767\n[0.2763209640979767]\nfeatures.17.conv.1.0.weight torch.Size([960, 1, 3, 3])\nIter:0 EigenValue: 0.007766475901007652\nIter:1 EigenValue: 15.84074592590332\nIter:2 EigenValue: 22.26443099975586\nIter:3 EigenValue: 22.31415367126465\n[22.31415367126465]\nfeatures.17.conv.1.1.weight torch.Size([960])\nIter:0 EigenValue: 0.0023117836099117994\nIter:1 EigenValue: 0.1354416012763977\nIter:2 EigenValue: 0.20413969457149506\nIter:3 EigenValue: 0.20631825923919678\n[0.20631825923919678]\nfeatures.17.conv.2.weight torch.Size([320, 960, 1, 1])\nIter:0 EigenValue: 0.0036027496680617332\nIter:1 EigenValue: 30.529863357543945\nIter:2 EigenValue: 132.20469665527344\nIter:3 EigenValue: 141.96263122558594\nIter:4 EigenValue: 142.322021484375\n[142.322021484375]\nfeatures.17.conv.3.weight torch.Size([320])\nIter:0 EigenValue: 0.0007945210672914982\nIter:1 EigenValue: 0.028513187542557716\nIter:2 EigenValue: 0.03003525361418724\n[0.03003525361418724]\nfeatures.18.0.weight torch.Size([1280, 320, 1, 1])\nIter:0 EigenValue: 0.0002910780895035714\nIter:1 EigenValue: 0.7390462160110474\nIter:2 EigenValue: 0.9254473447799683\nIter:3 EigenValue: 1.0348632335662842\nIter:4 EigenValue: 1.1294033527374268\n[1.1294033527374268]\nfeatures.18.1.weight torch.Size([1280])\nIter:0 EigenValue: 0.0001283142773900181\nIter:1 EigenValue: 0.0013308526249602437\nIter:2 EigenValue: 0.0018984696362167597\nIter:3 EigenValue: 0.002138829557225108\nIter:4 EigenValue: 0.0022768420167267323\n[0.0022768420167267323]\nclassifier.1.weight torch.Size([1000, 1280])\nIter:0 EigenValue: 6.0286522057140246e-05\nIter:1 EigenValue: 0.35807743668556213\nIter:2 EigenValue: 0.46231526136398315\nIter:3 EigenValue: 0.49458158016204834\nIter:4 EigenValue: 0.5115610957145691\n[0.5115610957145691]\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.DataFrame.from_dict({'name': names, 'eig':eig})","metadata":{"execution":{"iopub.status.busy":"2024-03-24T16:49:35.647554Z","iopub.execute_input":"2024-03-24T16:49:35.648288Z","iopub.status.idle":"2024-03-24T16:49:35.656021Z","shell.execute_reply.started":"2024-03-24T16:49:35.648246Z","shell.execute_reply":"2024-03-24T16:49:35.654733Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df.to_csv('eig.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T16:49:35.728376Z","iopub.execute_input":"2024-03-24T16:49:35.729258Z","iopub.status.idle":"2024-03-24T16:49:35.742163Z","shell.execute_reply.started":"2024-03-24T16:49:35.729214Z","shell.execute_reply":"2024-03-24T16:49:35.740729Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/eig.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-25T09:47:14.090935Z","iopub.execute_input":"2024-03-25T09:47:14.091606Z","iopub.status.idle":"2024-03-25T09:47:15.139462Z","shell.execute_reply.started":"2024-03-25T09:47:14.091566Z","shell.execute_reply":"2024-03-25T09:47:15.137674Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meig.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eig.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'eig.csv'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}